---
title: "Student Success - clean data"
author: "Jemma Marcus-Shi & Linjie Zhu"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    code_folding: show
    df_print: paged
    number_sections: yes
    theme: readable
    toc: yes
    toc_float: yes
    code_download: yes
  word_document:
    toc: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Audience and Purpose

The purpose of our project is to help Mr. Kirk Bogard raise fund for Farmer School of Business. We will create several maps to clearly show companies in which region are more valuable to try to build external relationships. Audience of our project is shared work producers including people who do the same job as Mr. Kirk Bogard in a team, users who need to know how it done and how to done it better.

# Value Proposition

![](poster%20Value%20proposition%20canvas%20simple%20white.png)

## Data Description

Our group will be using the FSB data on the employment status of graduates in order to find information about geographic trends The data file is includes survey data on where students are going, what are students' salaries, job opportunities in each region between 2019 to 2021.

# Documented Code to Preprocesses Data

```{r}
## Load necessary libraries
library(dplyr)

## Load the data
df <- read.csv("FSB_Survey_Dirty.csv")

## Data overview
head(df)

## Check missing values
colSums(is.na(df))

## Delete "X" variable
df <- df[-which(names(df) == "X")]

## Delete columns for "BBRJ", "Study Abroad Courtesy Account", and "Transfer Work" due to lack of understanding and relevance
df <- df[, !(names(df) %in% c("BBRJ","Study.Abroad.Courtesy.Account", "Transfer.Work..Pre.Banner."))]

## Delete columns due to relevance to research question
df <- df[, !(names(df) %in% c("nmajor", "Business.Direct.Admit", "First.Generation.College.Stdnt", "Combined.Bacc.and.Masters", "Dean.s.List", "FSB.Scholars", "Honors.Program", "President.s.List", "Cum.Laude", "Magna.Cum.Laude", "Summa.Cum.Laude", "University.Honors","UniversityHonors.w.Distinction", "year.x", "latin_honors", "survey_gradprogram", "survey_gradschool", 
"survey_internfour","survey_internone", "survey_internships", "survey_internthree", "survey_interntwo"))]

## Check for changes
head(df)

## Check dimensions
dim(df)

## Remove rows that contain a null value for "survey_state"
df <- df[!is.na(df$survey_state), , drop = FALSE]

## Check data again
str(df)

# Fill missing values in columns 'survey_city', 'survey_company', and 'survey_deptfunc' with "Unknown"
df[, c("survey_city", "survey_company", "survey_deptfunc")] <- lapply(df[, c("survey_city", "survey_company", "survey_deptfunc")], function(x) ifelse(is.na(x), "Unknown", x))

# Fill missing values in columns 'survey_offers', 'survey_pref_field', and 'survey_pref_loc' with "None"
df[, c("survey_offers", "survey_pref_field", "survey_pref_loc")] <- lapply(df[, c("survey_offers", "survey_pref_field", "survey_pref_loc")], function(x) ifelse(is.na(x), "None", x))

# Fill missing values in the 'survey_salary' column with the mean salary
df$survey_salary[is.na(df$survey_salary)] <- mean(df$survey_salary, na.rm = TRUE)

## Save the modified data to a new CSV file
write.csv(df, file = "FSB_Survey.csv", row.names = FALSE)

```

# Explanation on Preprocess Code

We start with analyze the data structure and missing values for each variable. Then we delete several variables which are don't relate to this project or not explained clearly, including BBRJ, Study Abroad Courtesy Account, Transfer Work, latin_honors and so on to make our analysis process easier. Continuously, for accuracy of our analysis, we remove the missing values from the rest variables and checked our data. Moreover, for some variables like 'survey_offers', 'survey_cities' relate to our analysis, we impute them with "Unkown" or "None". Finally, we documented the new data into "FSB_Survey.csv". This document is what we will use for analysis.

# Computering Environment

We run the code R.Version（） to figure out the version of r studio to ensure our code can be reproduce. Also, we will use the "FSB_Survey_Dirty.csv" as our original documents before clean data. And keep all codes for cleaning data in this file and document those new data into "FSB_Survey.csv". Thus, we can rerun the code to ensure reproductible.
