---
title: "Student Success - final project"
author: "Jemma Marcus-Shi & Linjie Zhu"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    code_folding: show
    df_print: paged
    number_sections: yes
    theme: readable
    toc: yes
    toc_float: yes
    code_download: yes
  word_document:
    toc: no
---

# Project Statement

The purpose of our project is to help Mr. Kirk Bogard, Associate Vice President for Development and External Relations, raise funds for Farmer School of Business. We will create several graphs and maps to clearly show the distribution of FSB recent graduates in the US to indicate where it may be most valuable to try and build external relationships. The audience of our project are shared work producers including Mr. Bogard and his team of people who do the same job as Mr. Kirk Bogard, users who need to know how it is done, and how to do it better.

![](images/poster%20Value%20proposition%20canvas%20simple%20white.png)

# Clean Data

## Data Description
We have three years of data representing FSB graduates in 2019, 2020, and 2021. The dataset provided had 42 variables. The source is either derived by Professor Jones-Farmer during data cleaning/merging, from the Oracle Business Intelligence Enterprise Edition (OBIEE) maintained by Miami administration, or from the self reported senior survey. The files have been cleaned and merged into one file.

The meaning of the columns in the datafile are as follows:

\* nmajor: numeric,derived, the number of majors

\* major1: text, OBIEE, first major

\* major 2: text, OBIEE, second major

\* BBRJ: binary, OBIEE, an attribute of a student, but we do not know what this stands for

\* Business Direct Admit: binary, OBIEE, a direct admit to FSB as a first year

\* Combined Cacc and Masters: binary, OBIEE, combined degree student

\* Dean's List: binary, OBIEE, achieve dean's list status at least once

\* First Generation College Stdnt: binary, OBIEE, first generation student status

\* FSB Scholars: binary, OBIEE, FSB scholars program

\* Honors Program: binary, OBIEE, member of University honors program

\* President's list: binary, OBIEE, achieved president's list at least once

\* Study Abroad Courtesy Account: binary, OBIEE, do not know meaning

\* Transfer Work: binary, OBIEE, do not know exact meaning

\* Cum Laude: binary, OBIEE, graduated Cum Laude

\* Magna Cum Laude: binary, OBIEE, graduated Magna Cum Laude

\* Summa Cum Laude: binary, OBIEE, graduated Summa Cum Laude

\* University Honors: binary, OBIEE, graduated with University Honors

\* University Honors w/Distinction: binary, OBIEE, graduated with University Honors with Distinction

\* minor1: text, OBIEE, first listed minor

\* minor2: text, OBIEE, second listed minor

\* IPEDS.Race.Ethnicity: text, OBIEE, race/ethnicity

\* Gender: text, OBIEE, sex

\* GPA.Range: text, OBIEE, GPA within a .5 range

\* Term.Code: numeric, OBIEE, First four digits are the graduation year (beginning in July, e.g. July 2020 is FY 2021). Last two digits is the term (10=fall, 15=winter, 20=spring, 30=summer).

\* Year.x: text, derived, first four digits of Term.Code stored as a character variable

\* latin_honors: text, survey, latin honors designation

\* survey_city: text, survey, student reported city in which their job is located

\* survey_company: text, survey, student reported company in which they accepted a job

\* survey_deptfunc: text, survey, student reported job function

\* survey_gradprogram: text, survey, student reported graduate program they will be attending

\* survey_gradschool: text, survey, stuent reported graduate school they will be attending

\* survey_internfour: text, survey, student reported fourth internship they held during college

\* survey_internthree: text, survey, student reported third internship they held during college

\* survey_interntwo: text, survey, student reported second internship they held during college

\* survey_internone: text, survey, student reported first internship they held during college

\* Survey_internships: text, survey, Student reported number of internships they held during college

\* survey_offers: text, survey, student reported number of offers for full time employment received

\* survey_plans: text, survey, student reported plans after graduation

\* survey_pref_field: text, survey, student reported whether working in preferred field

\* survey_pref_loc: text, survey, student reported whether working in preferred location

\* survey_salary: numeric, survey, student reported salary

\* survey_state: text, survey, student reported state in which job is located

The file we begin with has 3235 rows and 17 columns. The data that comes from the student survey has varying percentages of null variables. The variables that are most relevant to our research question are survey_city, survey_state, and survey_salary. Survey_city is missing 41% of values, survey_state is missing 40% of values, and survey_salary is missing 46% of values.

Our group will be using the FSB data on the employment location and salary of graduates in order to find information about geographic trends. The data file includes limited survey data on where students are located for their employment, what students' salaries are, and the job opportunities for Miami sutdents that existed in different regions between 2019 to 2021.

##### The necessary libraries are loaded into R {.unnumbered}

```{r}
library(dplyr)
```

##### The data is loaded and displayed to check the success of the loading {.unnumbered}

```{r}
df <- readRDS('FSB_BI_Survey_2019_2021.rds')
head(df)
```

##### Missing values are evaluated {.unnumbered}

```{r}
colSums(is.na(df))
```

##### Variables are removed due to lack of understanding, missing values, and relevance {.unnumbered}

```{r}
# Variables "BBRJ", "Study Abroad Courtesy Account", and "Transfer Work" are removed due to lack of understanding and missing variables

df <- df[, !(names(df) %in% c("BBRJ","Study Abroad Courtesy Account", "Transfer Work (Pre-Banner)"))]

# Variables without relevance to the research question are removed

df <- df[, !(names(df) %in% c("nmajor", "Business Direct Admit", "First Generation College Stdnt", "Combined Bacc and Masters", "Dean's List", "FSB Scholars", "Honors Program", "President's List", "Cum Laude", "Magna Cum Laude", "Summa Cum Laude", "University Honors","UniversityHonors w/Distinction", "year.x", "latin_honors", "survey_gradprogram", "survey_gradschool", "survey_internfour","survey_internone", "survey_internships", "survey_internthree", "survey_interntwo"))]
```

##### The data is displayed again and the dimensions are checked to confirm removal of variables {.unnumbered}

```{r}
head(df)
dim(df)
```

##### Rows that contain a null value for "survey_state" are removed {.unnumbered}

```{r}
df <- df[!is.na(df$survey_state), , drop = FALSE]
```

##### Only rows where "accepted fulltime job" is the value in "survey_plans" are kept {-}

```{r}
df <- df %>% filter(survey_plans == "accepted fulltime job")
```

##### The data is checked for remaining null values {.unnumbered}

```{r}
colSums(is.na(df))
```

##### Null values are imputed {.unnumbered}

```{r}
# Missing values in variables 'survey_city', 'survey_company', and 'survey_deptfunc' are imputed with "Unknown"

df[, c("survey_city", "survey_company", "survey_deptfunc")] <- lapply(df[, c("survey_city", "survey_company", "survey_deptfunc")], function(x) ifelse(is.na(x), "Unknown", x))

# Missing values in variables 'survey_offers', 'survey_pref_field', and 'survey_pref_loc' are imputed with "None"

df[, c("survey_offers", "survey_pref_field", "survey_pref_loc")] <- lapply(df[, c("survey_offers", "survey_pref_field", "survey_pref_loc")], function(x) ifelse(is.na(x), "None", x))

# The missing values in the 'survey_salary' variable are imputed with the mean salary

df$survey_salary[is.na(df$survey_salary)] <- mean(df$survey_salary, na.rm = TRUE)
```

##### The data is checked for remaining null values {.unnumbered}

```{r}
colSums(is.na(df))
```

##### 'survey_state' is converted to uppercase and spaces are removed {.unnumbered}

```{r}
df$survey_state <- toupper(df$survey_state)
df$survey_state <- trimws(df$survey_state)
```

##### state names are standardized to abbreviations and countries and cities outside the US are removed {.unnumbered}

```{r}
df$survey_state <- recode(df$survey_state,
  'ALABAMA' = 'AL',
  'ALASKA' = 'AK',
  'ARIZONA' = 'AZ',
  'ARKANSAS' = 'AR',
  'CALIFORNIA' = 'CA',
  'COLORADO' = 'CO',
  'CONNECTICUT' = 'CT',
  'DELAWARE' = 'DE',
  'FLORIDA' = 'FL',
  'GEORGIA' = 'GA',
  'IDAHO' = 'ID',
  'ILLINOIS' = 'IL',
  'INDIANA' = 'IN',
  'IOWA' = 'IA',
  'KANSAS' = 'KS',
  'KENTUCKY' = 'KY',
  'LOUISIANA' = 'LA',
  'MAINE' = 'ME',
  'MARYLAND' = 'MD',
  'MASSACHUSETTS' = 'MA',
  'MICHIGAN' = 'MI',
  'MINNESOTA' = 'MN',
  'MISSISSIPPI' = 'MS',
  'MISSOURI' = 'MO',
  'MONTANA' = 'MT',
  'NEBRASKA' = 'NE',
  'NEVADA' = 'NV',
  'NEW HAMPSHIRE' = 'NH',
  'NEW JERSEY' = 'NJ',
  'NEW MEXICO' = 'NM',
  'NEW YORK' = 'NY',
  'NORTH CAROLINA' = 'NC',
  'NORTH DAKOTA' = 'ND',
  'OHIO' = 'OH',
  'OKLAHOMA' = 'OK',
  'OREGON' = 'OR',
  'PENNSYLVANIA' = 'PA',
  'RHODE ISLAND' = 'RI',
  'SOUTH CAROLINA' = 'SC',
  'SOUTH DAKOTA' = 'SD',
  'TENNESSEE' = 'TN',
  'TEXAS' = 'TX',
  'UTAH' = 'UT',
  'VERMONT' = 'VT',
  'VIRGINIA' = 'VA',
  'WASHINGTON' = 'WA',
  'WEST VIRGINIA' = 'WV',
  'WISCONSIN' = 'WI',
  'WYOMING' = 'WY',
  'OH, USA' = 'OH',
  'OHIO/ UNITED STATES' = 'OH',
  'OH/US' = 'OH',
  'OHIO / THE UNITED STATES' = 'OH',
  'OHIO/UNITED STATES' = 'OH',
  'OH, USA' = 'OH',
  'OHIO / USA ' = 'OH',
  'OH/USA' = 'OH',
  'OHIO/UNITED STATES' = 'OH',
  'OHIO / UNITED STATES' = 'OH',
  'OHIO/USA' = 'OH',
  'OH, USA' = 'OH',
  'OHIO / USA' = 'OH',
  'IL/ USA' = 'IL',
  'ILLINOIS / USA' = 'IL',
  'ILLINOIS, USA' = 'IL',
  'ILLINOIS/USA' = 'IL',
  'ILLINOIS/ US' = 'IL',
  'IL, UNITED STATES' = 'IL',
  'IL, US' = 'IL',
  'IL, USA' = 'IL',
  'IL/USA' = 'IL',
  'BELIZE' = 'DELETE',
  'CANADA' = 'DELETE',
  'CHINA' = 'DELETE',
  'FUJIAN PROVINCE' = 'DELETE',
  'INDIA' = 'DELETE',
  'IRELAND' = 'DELETE',
  'MONTENEGRO' = 'DELETE',
  'TBA / USA' = 'DELETE',
  'TURKEY' = 'DELETE',
  'UNITED KINGDOM' = 'DELETE',
  'ZHEJIANG PROVINCE' = 'DELETE',
  'COLORADO/ UNITED STATES' = 'CO',
  'D.C.' = 'DC',
  'DISTRICT OF COLUMBIA' = 'DC',
  'WASHINGTON D.C/UNITED STATES' = 'DC',
  'GEORGIA, USA' = 'GA',
  'IN / USA' = 'IN',
  'MA / USA' = 'MA',
  'MASSACHUSETTS, USA' = 'MA',
  'MI / U.S.' = 'MI',
  'NEW YORK, USA' = 'NY',
  'TEXAS/ USA' = 'TX',
  'TX/USA' = 'TX',
  'UNITED STATES' = 'USA',
  'US' = 'USA',
  'VIRGINIA (VA)' = 'VA',
  'VIRGINIA/ USA' = 'VA',
  'WISCONSIN / USA' = 'WI',
  'MICHIGAN, DETROIT' = 'MI'
)
```

##### Rows with state values marked for deletion are removed {.unnumbered}

```{r}
df <- df %>% filter(survey_state != "DELETE")
```

##### 'survey_state' values are further standardized

```{r}
df$survey_state <- recode(df$survey_state,
  'COLORADO/ UNITED STATES' = 'CO',
  'D.C.' = 'DC',
  'DISTRICT OF COLUMBIA' = 'DC',
  'WASHINGTON D.C/UNITED STATES' = 'DC',
  'GEORGIA, USA' = 'GA',
  'IN / USA' = 'IN',
  'MA / USA' = 'MA',
  'MASSACHUSETTS, USA' = 'MA',
  'MI / U.S.' = 'MI',
  'NEW YORK, USA' = 'NY',
  'TEXAS/ USA' = 'TX',
  'TX/USA' = 'TX',
  'UNITED STATES' = 'USA',
  'US' = 'USA',
  'VIRGINIA (VA)' = 'VA',
  'VIRGINIA/ USA' = 'VA',
  'WISCONSIN / USA' = 'WI',
  'MICHIGAN, DETROIT' = 'MI'
)
```

##### 'survey_city' column is standardized and errors are amended {.unnumbered}

```{r}
df$survey_city <- toupper(df$survey_city)
df$survey_city <- trimws(df$survey_city)
```

```{r}
df$survey_city <- recode(df$survey_city,
  'NEW YORK CITY' = 'NEW YORK',
  'NYC' = 'NEW YORK',
  'CINCINATTI' = 'CINCINNATI',
  'WITCHITA' = 'WICHITA',
  'MILWAUKWEE' = 'MILWAUKEE',
  'CINCINNATI, OH' = 'CINCINNATI')
```

##### Rows with missing values in 'survey_city' are removed {.unnumbered}

```{r}
df <- df %>% filter(!is.na(survey_city))
```

##### The modified data is saved to a new CSV file {.unnumbered}

```{r}
write.csv(df, file = "FSB_Survey.csv", row.names = FALSE)
```

# Explanation of Cleaning the Data

We started by getting an overview the data structure and missing values for each variable. Then, we deleted several variables which do not relate to our project or are not clear enough to be useful, including BBRJ, Study Abroad Courtesy Account, Transfer Work, latin_honors and 25 others. We deleted these variables because they were not relevant to our research question. We then removed the rows that contained missing values for the state the job was in, as no information could be gathered for the project without this information. . For some variables such as 'survey_offers', 'survey_cities' we imputed them with "Unknown" or "None" to make clear the meaning of the null values. We also imputed the salary with the mean in preparation for the possibility of using that variable for further analysis requiring numeric data. Finally, we exported the cleaned data into "FSB_Survey.csv" in order to use for future analysis.

# Computing Environment

```{r}
sessionInfo()
```

We ran the code sessionInfo() function to determine the version of r studio used to ensure our code can be reproduced. We have also saved our original file "FSB_BI_Survey_2019_2021.rds". Thus, we can rerun the code in the future to ensure reproducibility.

# Dashboard

### Question 1: Students' average salary by region/state

We will calculate the average salary for students by state or region, depending on the differences we find after analysis. The graph will only show the 10 states have the highest average salaries since there are too many states.

### Question 2: City rank by job opportunities

We will summarize the number of students employed by city and rank those cities by frequency. Thus, we can find which cities give our students the most job opportunities. It will also allow our client to be aware of which cities should be the focus of fundraising efforts. 

# Region/State by Average Salaries {data-orientation="columns"}

```{r,echo=FALSE}
library(dplyr)
library(readr)
library(magrittr)

df <- read.csv('FSB_Survey.csv')
cities = read.csv('uscities.csv')
```
```{r}
df <- df %>% mutate(city_state = paste(survey_city, ", ", survey_state))
cities <- cities %>% mutate(city_state = toupper(paste(city, ", ", state_id)))
```

```{r}
df_final <- left_join(df, cities %>% select(city_state, lat, lng), by = "city_state")
```

```{r}
head(df_final)
df %>% count(city_state) %>% arrange(desc(n)) %>% head(10)
```

```{r}
grouped_data <- df %>%
  group_by(survey_state) %>% 
  summarize(AvgSalary = mean(survey_salary),
            OfferCount = n()) %>%  
  filter(OfferCount >= 10) 
```


## Column {data-width="400"}

### Add Bar Charts and/or Scatterplot Map to show Highest Region/State

```{r,echo=FALSE}
library(ggplot2)

# Sort the grouped data by AvgSalary in descending order
grouped_data <- grouped_data %>%
  arrange(desc(AvgSalary))

# Take the top 10 states
top_10_states <- head(grouped_data, 10)

# Create a bar chart for the top 10 states
ggplot(top_10_states, aes(x = reorder(survey_state, -AvgSalary), y = AvgSalary)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  labs(x = "State", y = "Average Salary") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

# City Rank by Job Opportunities {data-orientation="columns"}

```{r}
offers_by_city <- df_final %>%
  group_by(city_state) %>%  
  summarize(Offer_Count = n())

ranked_offers <- offers_by_city %>%
  arrange(desc(Offer_Count)) %>%
  mutate(Rank = row_number())
```

## Column {data-width="400"}

### Add Bar Charts

```{r,echo=FALSE}
library(ggplot2)

top_10_cities <- head(ranked_offers, 10)

# Create a bar chart for the top 10 cities
ggplot(top_10_cities, aes(x = reorder(city_state, -Offer_Count), y = Offer_Count)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  labs(x = "City", y = "Job Opportunities") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

## Column {data-width="400"}
```{r}
library(mapview)
library(sf)
city_map_df = data.frame(df_final$lng, df_final$lat, df_final$city_state)
city_map_df = na.omit(city_map_df)
city_map_sdf = st_as_sf(city_map_df,
                        coords=c("df_final.lng", "df_final.lat"), crs=4326)
mapview(city_map_sdf, label=city_map_sdf$city_state)
```

```{r}
library(leaflet)

# Create a leaflet map for the top 10 cities
m <- leaflet(data = city_map_df) %>%
  addTiles() %>%
  setView(lng = -98, lat = 39, zoom = 4) %>%
  addCircleMarkers(
    radius = 8,
    color = "blue",
    label = ~df_final.city_state,
    lat = ~df_final.lat,
    lng = ~df_final.lng,
    popup = ~paste("City:", df_final.city_state)
 )
m
```

# sessionInfo {data-orientation="columns"}

```{r}
sessionInfo()
```
